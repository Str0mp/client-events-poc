# CLIENT-EVENTS-POC

## Proyecto

**Tecnolog√≠a:** NestJS (Node.js + TypeScript)

**Instalaci√≥n y arranque:**

```bash
git clone <repo-url> client-events-poc
cd client-events-poc
npm install
npm run start:dev
```

**Endpoints:**

* `GET /benefits/process`
  [http://localhost:3000/benefits/process](http://localhost:3000/benefits/process)

  * Ejecuta el c√°lculo de beneficios y escribe el archivo `src/assets/benefits.json`.

* `GET /history/:clientId`
  e.g. [http://localhost:3000/history/client\_7](http://localhost:3000/history/client_7)

  * Devuelve la informaci√≥n hist√≥rica por REST sin guardar ning√∫n archivo.

---

## üß† Parte 1.1

**¬øC√≥mo manejar tantos datos y procesarlos sin bloquear la API?**

* **Colas de procesamiento**
  Utilizar Queue para encolar la ejecuci√≥n de `processBenefits()`.

  * La API responde inmediatamente.
  * La cola procesa en background y reintenta autom√°ticamente en caso de fallo.

* **Base de datos relacional**
  Migrar los eventos a una tabla con √≠ndices compuestos `(client_id, store_id, timestamp)`.

  * Guardar en otra tabla la ‚Äú√∫ltima fecha procesada‚Äù por cliente/tienda para procesar solo eventos nuevos.
  * Evita releer y reprocesar todo el hist√≥rico en cada ejecuci√≥n.

* **Cache de rachas**
  Almacenar en cach√© el contador de visitas consecutivas por `client::store`.

  * Al reiniciar el job, recuperas la √∫ltima racha sin tener que leer todo el historial.
  * Acelera el c√°lculo de nuevos beneficios.

* **Pruebas unitarias**
  Cubrir todos los casos:

  1. Exactamente 5 visitas ‚Üí 1 beneficio.
  2. 6 visitas seguidas ‚Üí sigue siendo 1 beneficio (no lo incremente).
  3. Recarga en medio ‚Üí rompe la racha.
  4. Rachas m√∫ltiples ‚Üí detecta beneficios adicionales.
  5. Sin racha ‚Üí devuelve array vac√≠o.

---

## ‚úçÔ∏è Parte 2

### Limitaciones de la soluci√≥n actual

1. **Carga completa en memoria**

   * `fs.readFileSync` lee todo el JSON de eventos; dependiente de RAM y CPU.
2. **Reprocesamiento total**

   * Cada ejecuci√≥n itera **todo** el archivo, sin aprovechar lo ya procesado.
3. **Lectura/Escritura de ficheros**

   * Bloquean la ejecuci√≥n. Durante lectura/escritura no se atienden otras peticiones.

### ¬øQu√© pasar√≠a con 100 000 eventos diarios?

* El archivo crecer√≠a a millones de registros en pocas semanas, volviendo la lectura y el parseo cada vez m√°s lentos (segundos o minutos).
* Las peticiones bloquear√≠an o har√≠an timeout mientras dure la lectura/escritura.
* El uso de memoria explotar√≠a y la CPU se saturar√≠a al ordenar y filtrar millones de objetos.
* El coste en producci√≥n se disparar√≠a, requiriendo instancias con mucha RAM y CPU solo para procesar el JSON.
